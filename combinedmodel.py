# -*- coding: utf-8 -*-
"""CombinedModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YSzTw7PKGJ6fwCqmZxsA-Pi13Fu4eMm-
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install transformers

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.feature_extraction.text import TfidfVectorizer


from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_validate, cross_val_score, train_test_split
from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge
from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier, RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.pipeline import Pipeline
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from gensim.models import Word2Vec



import matplotlib.pyplot as plt # data visualisation
import seaborn as sns  # data visualisation
# %matplotlib inline
import os


import torch
from transformers import BertTokenizer, BertModel


import numpy as np

"""# Loading and Preparing Data"""

CBD = pd.read_csv('/content/drive/MyDrive/448 - Project/CollegeBasketballPlayers2009-2021.csv')
TextAndNBA = pd.read_csv('/content/drive/MyDrive/448 - Project/Tdata/TextPlusNBA.csv')

CBD = CBD.dropna()

CBD = CBD.drop(['Unnamed: 64', 'Unnamed: 65'], axis=1)

CBD['GP'] = CBD['GP'].astype(int)
CBD['Min_per'] = CBD['Min_per'].astype(float)

CBD.head()

CBD.columns

CBD = CBD.drop(['year'], axis=1)

TextAndNBA.columns

TextAndNBA = TextAndNBA.drop(['GP', 'FTM', 'FTA'], axis=1)

TextAndNBA.head()

CBD = CBD.rename(columns={'player_name': "name"})
merged_df = pd.merge( TextAndNBA, CBD, on="name", how='inner')
print(len(merged_df))
print(len(TextAndNBA))
print(len(CBD))
print(merged_df.head())

CBD = CBD.rename(columns={'player_name': "name"})
merg = pd.merge( TextAndNBA, CBD, on="name", how='left')
print(len(merg))
print(len(TextAndNBA))
print(len(CBD))
print(merg.head())
print(merg.columns)

print(merged_df.head())
print(len(merged_df))
print(merged_df["name"].head())
print(merged_df[merged_df["name"] == "Jordan Hill"]["year"])

print(merged_df.columns)

print(len(merged_df[merged_df['year'] >= 2019]))
print(len(merged_df.index[merged_df['year'] < 2016]))
print(len(merged_df.index[merged_df['year'] >= 2016]))

Performance = ["FG%", "PR", "3P%", "PF", "PTS"]

TrainIndex = list(merged_df.index[merged_df['year'] < 2016])
print(len(TrainIndex))

"""## All Embeddings"""



TextAndNBA = merged_df

tfidf_vectorizer = TfidfVectorizer(ngram_range =(1,1))

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf_unigrams = tfidf_vectorizer.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf_unigrams.shape)

# EXTRA BELOW:

unigrams = tfidf_vectorizer.get_feature_names_out()


# create a Pandas dataframe to store the TF-IDF unigram scores
tfidf_unigram_df = pd.DataFrame(tfidf_unigrams.toarray(), columns=unigrams)

df2 = TfidfVectorizer(ngram_range =(1,1), min_df=2)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf2_unigrams = df2.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf2_unigrams.shape)

df3 = TfidfVectorizer(ngram_range =(1,1), min_df=3)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf3_unigrams = df3.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf3_unigrams.shape)


df4 = TfidfVectorizer(ngram_range =(1,1), min_df=4)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf4_unigrams = df4.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf4_unigrams.shape)


df5 = TfidfVectorizer(ngram_range =(1,1), min_df=5)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf5_unigrams = df5.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf5_unigrams.shape)

# For test data


# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf_unigramsTest = tfidf_vectorizer.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf_unigramsTest.shape)

tfidf2_unigramsTest = df2.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf3_unigramsTest = df3.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf4_unigramsTest = df4.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf5_unigramsTest = df5.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf_vectorizer_bi = TfidfVectorizer(ngram_range =(2,2))

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf_bigrams = tfidf_vectorizer_bi.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf_bigrams.shape)

# EXTRA BELOW:

# get the feature names (i.e., the unigrams)
#x_array =
#print(tfidf_unigrams.toarray())
bigrams = tfidf_vectorizer_bi.get_feature_names_out()


# create a Pandas dataframe to store the TF-IDF unigram scores
tfidf_bigram_df = pd.DataFrame(tfidf_bigrams.toarray(), columns=bigrams)

dfb2 = TfidfVectorizer(ngram_range =(2,2), min_df=2)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf2_bigrams = dfb2.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf2_bigrams.shape)

dfb3 = TfidfVectorizer(ngram_range =(2,2), min_df=3)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf3_bigrams = dfb3.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf3_bigrams.shape)


dfb4 = TfidfVectorizer(ngram_range =(2,2), min_df=4)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf4_bigrams = dfb4.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf4_bigrams.shape)


dfb5 = TfidfVectorizer(ngram_range =(2,2), min_df=5)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf5_bigrams = dfb5.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf5_bigrams.shape)

tfidf_bigramsTest = tfidf_vectorizer_bi.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf_bigramsTest.shape)


tfidf2_bigramsTest = dfb2.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf3_bigramsTest = dfb3.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf4_bigramsTest = dfb4.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf5_bigramsTest = dfb5.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf_vectorizer_ubi = TfidfVectorizer(ngram_range =(1,2))

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf_ubigrams = tfidf_vectorizer_ubi.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf_ubigrams.shape)

# EXTRA BELOW:

# get the feature names (i.e., the unigrams)
#x_array =
#print(tfidf_unigrams.toarray())
ubigrams = tfidf_vectorizer_ubi.get_feature_names_out()


# create a Pandas dataframe to store the TF-IDF unigram scores
tfidf_ubigram_df = pd.DataFrame(tfidf_ubigrams.toarray(), columns=ubigrams)

dfub2 = TfidfVectorizer(ngram_range =(1,2), min_df=2)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf2_ubigrams = dfub2.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf2_ubigrams.shape)

dfub3 = TfidfVectorizer(ngram_range =(1,2), min_df=3)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf3_ubigrams = dfub3.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf3_ubigrams.shape)


dfub4 = TfidfVectorizer(ngram_range =(1,2), min_df=4)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf4_ubigrams = dfub4.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf4_ubigrams.shape)


dfub5 = TfidfVectorizer(ngram_range =(1,2), min_df=5)

# fit and transform the text data to calculate the TF-IDF unigram scores
tfidf5_ubigrams = dfub5.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf5_ubigrams.shape)

tfidf_ubigramsTest = tfidf_vectorizer_ubi.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])
print(tfidf_ubigramsTest.shape)


tfidf2_ubigramsTest = dfub2.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf3_ubigramsTest = dfub3.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf4_ubigramsTest = dfub4.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

tfidf5_ubigramsTest = dfub5.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])

text_data = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'].values.tolist()
tokenized_data = [text.split() for text in text_data]
VECTOR_SIZE = 60
model = Word2Vec(tokenized_data, min_count=3, vector_size=VECTOR_SIZE)
embedded_data = []
for text in tokenized_data:
    embedded_text = [model.wv[word] for word in text if word in model.wv.key_to_index]
    embedded_data.append(embedded_text)

lengts = np.empty(0)
for text in embedded_data:
  lengts = np.append(lengts, len(text))

print(lengts.max())
print(lengts.min())
MAXWORDS = int(lengts.max())

word2vec_embed = np.empty((0,MAXWORDS,VECTOR_SIZE))
for document in embedded_data:
  doc_vec = np.empty((0, VECTOR_SIZE))
  for word in document:

    doc_vec = np.vstack((doc_vec, np.reshape(word, (1, VECTOR_SIZE))))

  if doc_vec.shape[0] < MAXWORDS:
    n = MAXWORDS - doc_vec.shape[0]
    doc_vec = np.pad(doc_vec, [(0, n), (0 , 0)], mode = 'constant')

  elif doc_vec.shape[0] > MAXWORDS:
    doc_vec = doc_vec[:MAXWORDS, :]



  word2vec_embed = np.vstack((word2vec_embed, np.reshape(doc_vec, (1, MAXWORDS, VECTOR_SIZE))))

word2vec_embed = np.reshape(word2vec_embed, (word2vec_embed.shape[0],  word2vec_embed.shape[1] * word2vec_embed.shape[2]   ))
print(word2vec_embed.shape)

text_data = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'].values.tolist()
tokenized_data = [text.split() for text in text_data]
model = Word2Vec(tokenized_data, min_count=3, vector_size=VECTOR_SIZE)
embedded_data = []
for text in tokenized_data:
    embedded_text = [model.wv[word] for word in text if word in model.wv.key_to_index]
    embedded_data.append(embedded_text)


word2vec_embedTest = np.empty((0,MAXWORDS,VECTOR_SIZE))
for document in embedded_data:
  doc_vec = np.empty((0, VECTOR_SIZE))
  for word in document:

    doc_vec = np.vstack((doc_vec, np.reshape(word, (1, VECTOR_SIZE))))

  if doc_vec.shape[0] < MAXWORDS:
    n = MAXWORDS - doc_vec.shape[0]
    doc_vec = np.pad(doc_vec, [(0, n), (0 , 0)], mode = 'constant')

  elif doc_vec.shape[0] > MAXWORDS:
    doc_vec = doc_vec[:MAXWORDS, :]



  word2vec_embedTest = np.vstack((word2vec_embedTest, np.reshape(doc_vec, (1, MAXWORDS, VECTOR_SIZE))))



word2vec_embedTest = np.reshape(word2vec_embedTest, (word2vec_embedTest.shape[0],  word2vec_embedTest.shape[1] * word2vec_embedTest.shape[2]   ))
print(word2vec_embedTest.shape)

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')

## TAKES AROUND 10 MINUTES


# Load text data from pandas DataFrame
texts = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'].tolist()

# Tokenize text using BERT tokenizer
tokens = tokenizer.batch_encode_plus(texts,
                                      add_special_tokens=True,
                                      padding=True,
                                      truncation=True,
                                      return_tensors='pt')

# Generate BERT embeddings for the input text
with torch.no_grad():
    embeddings = model(tokens['input_ids'], attention_mask=tokens['attention_mask'])[0]

# Extract the embeddings for the first token (the [CLS] token)
bert_embeddings = embeddings[:, 0, :].numpy()

texts = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'].tolist()

# Tokenize text using BERT tokenizer
tokens = tokenizer.batch_encode_plus(texts,
                                      add_special_tokens=True,
                                      padding=True,
                                      truncation=True,
                                      return_tensors='pt')

# Generate BERT embeddings for the input text
with torch.no_grad():
    embeddings = model(tokens['input_ids'], attention_mask=tokens['attention_mask'])[0]

# Extract the embeddings for the first token (the [CLS] token)
bert_embeddingsTest = embeddings[:, 0, :].numpy()
print(bert_embeddingsTest.shape)

ALL_DATA = {"unigram_tfidf": tfidf_unigrams, "unigram_tfidf2": tfidf2_unigrams, "unigram_tfidf3": tfidf3_unigrams, "unigram_tfidf4": tfidf4_unigrams, "unigram_tfidf5": tfidf5_unigrams,
            "bigram_tfidf": tfidf_bigrams, "bigram_tfidf2": tfidf2_bigrams, "bigram_tfidf3": tfidf3_bigrams, "bigram_tfidf4": tfidf4_bigrams, "bigram_tfidf5": tfidf5_bigrams,
            "ubigram_tfidf": tfidf_ubigrams, "ubigram_tfidf2": tfidf2_ubigrams, "ubigram_tfidf3": tfidf3_ubigrams, "ubigram_tfidf4": tfidf4_ubigrams, "ubigram_tfidf5": tfidf5_ubigrams,
            "word2vec": word2vec_embed, "bert_embeddings": bert_embeddings}
ALL_TEST = {"unigram_tfidf": tfidf_unigramsTest, "unigram_tfidf2": tfidf2_unigramsTest, "unigram_tfidf3": tfidf3_unigramsTest, "unigram_tfidf4": tfidf4_unigramsTest, "unigram_tfidf5": tfidf5_unigramsTest,
            "bigram_tfidf": tfidf_bigramsTest, "bigram_tfidf2": tfidf2_bigramsTest, "bigram_tfidf3": tfidf3_bigramsTest, "bigram_tfidf4": tfidf4_bigramsTest, "bigram_tfidf5": tfidf5_bigramsTest,
            "ubigram_tfidf": tfidf_ubigramsTest, "ubigram_tfidf2": tfidf2_ubigramsTest, "ubigram_tfidf3": tfidf3_ubigramsTest, "ubigram_tfidf4": tfidf4_ubigramsTest, "ubigram_tfidf5": tfidf5_ubigramsTest,
            "word2vec": word2vec_embedTest, "bert_embeddings": bert_embeddingsTest}

"""# T Models

## Regression Models
"""

TRegModels = {}
RegEmbedding = ["ubigram_tfidf4", "ubigram_tfidf4", "unigram_tfidf3", "unigram_tfidf5", "unigram_tfidf"]
Estimators = [25, 100, 100, 50, 75]
Features = ['log2', 'special', 'sqrt', 'sqrt', 'sqrt']


for i, perf in enumerate(Performance):
  YTDATA = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), f'{perf}'].values

  TRegModels[perf] = None
  XTData = ALL_DATA[RegEmbedding[i]]
  num_estimator = Estimators[i]
  num_feature = Features[i]
  if num_feature == "special":
      num_feature = int(XTData.shape[1] / 3)




  sample_tree = DecisionTreeRegressor(max_features=num_feature)
  adareg = AdaBoostRegressor(estimator = sample_tree, n_estimators= num_estimator)
  scores = cross_validate(adareg, XTData, YTDATA, cv=10, return_estimator=True)
  mean_performance = scores['test_score'].mean()
  print(f"mean_performance for {perf}: {mean_performance}")

  bestModelIndex = np.argmax(scores['test_score'])


  TRegModels[perf] = scores["estimator"][bestModelIndex]

"""## Classification Models"""

perf_bests = []
perf_models = []
perf_model_names = []
num_estimators = list(range(0, 111, 5))
num_estimators[0] = 1

best_estimators = []
best_features = []


num_features = ["sqrt", "log2", "special", "auto"]

for perf in Performance:
  y = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), f'AoB{perf}'].values
  best_performance = 0
  best_scores = None
  best_embedding = ""
  best_esti = 0
  best_feature = None

  for num_feature in num_features:
    for num_estimator in num_estimators:
      for embeddingType in ALL_DATA.keys():
        X = ALL_DATA[embeddingType]

        if num_feature == "special":
          num_feature = int(X.shape[1] / 3)

        sample_tree = DecisionTreeClassifier(max_features=num_feature)
        adareg = AdaBoostClassifier(estimator = sample_tree, n_estimators= num_estimator)
        scores = cross_validate(adareg, X, y, cv=10, return_estimator=True)
        mean_performance = scores['test_score'].mean()
        if mean_performance > best_performance:
          best_performance = mean_performance
          best_scores = scores
          best_embedding = embeddingType
          best_esti = num_estimator
          best_feature = num_feature
  print(f"Best performance for AoB{perf}: {best_performance}")
  print(f"Used model {best_embedding}")
  print(f"Best Estimator {best_esti}")
  print(f"Best Feature {best_feature}")


  best_features.append(best_feature)
  best_estimators.append(best_esti)
  bestModelIndex = np.argmax(best_scores['test_score'])
  perf_bests.append(best_performance)
  perf_models.append(best_scores["estimator"][bestModelIndex])
  perf_model_names.append(best_embedding)



TClassModels = {}
ClassEmbedding = {}

for i, perf in enumerate(Performance):
  TClassModels[perf] = perf_models[i]
  ClassEmbedding[perf] = perf_model_names[i]

# ClassEmbedding = ["word2vec", "ubigram_tfidf", "bigram_tfidf5", "unigram_tfidf", "bigram_tfidf2"]
# Estimators = [70, 35, 20, 110, 85]
# Features = ['auto', 'sqrt', 'auto', 'auto', 'auto']


# TClassModels = {}


# for i, perf in enumerate(Performance):
#   YTDATA = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), f'AoB{perf}'].values

#   TClassModels[perf] = None
#   XTData = ALL_DATA[ClassEmbedding[i]]
#   num_estimator = Estimators[i]
#   num_feature = Features[i]
#   if num_feature == "special":
#       num_feature = int(XTData.shape[1] / 3)




#   sample_tree = DecisionTreeClassifier(max_features=num_feature)
#   adareg = AdaBoostClassifier(estimator = sample_tree, n_estimators= num_estimator)
#   scores = cross_validate(adareg, XTData, YTDATA, cv=10, return_estimator=True)
#   mean_performance = scores['test_score'].mean()
#   print(f"mean_performance for {perf}: {mean_performance}")

#   bestModelIndex = np.argmax(scores['test_score'])


#   TClassModels[perf] = scores["estimator"][bestModelIndex]

cperf = "PTS"
feature_importance = np.mean([
    tree.feature_importances_ for tree in TClassModels[cperf].estimators_
], axis=0)

# Create a dictionary of feature importance values
print(ALL_DATA[ClassEmbedding[cperf]].shape)
print(feature_importance)
print(feature_importance.shape)
#print(tfidf_ubigram_df)


bigrams3 = dfb3.get_feature_names_out()


# create a Pandas dataframe to store the TF-IDF unigram scores
tfidf_bigram_df3 = pd.DataFrame(tfidf3_bigrams.toarray(), columns=bigrams3)

ThingImLookingAt = tfidf_bigram_df3


# Create a dictionary of feature importance values
feature_importance_dict = dict(zip(ThingImLookingAt.columns, feature_importance))

# Print the feature importance values
for feature, importance in feature_importance_dict.items():
    print(f"Feature '{feature}': Importance = {importance:.4f}")

# Print the feature importance values
# for feature, importance in feature_importance_dict.items():
#     print(f"Feature '{feature}': Importance = {importance:.4f}")

sorted_items = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)[:10]


# Extract the keys and values from the sorted items
keys = [item[0] for item in sorted_items]
values = [item[1] for item in sorted_items]

# Print the keys and values
print("Keys for the top 10 highest values:")
print(keys)
print("Values for the top 10 highest values:")
print(values)

for i, key in enumerate(keys):
  print(f"{key}: {values[i]}")

from sklearn.tree import export_text
decision_tree = TClassModels[f"{cperf}"].estimators_[0]
decision_rules = export_text(decision_tree, feature_names=ThingImLookingAt.columns.tolist())

# Print the decision rules or splits
print("Decision rules or splits for the first decision tree:")
print(decision_rules)

from sklearn.tree import export_graphviz

# Creates dot file named tree.dot
export_graphviz(
            decision_tree,
            out_file =  "myTreeName.dot",
            feature_names = list(ThingImLookingAt.columns),
            filled = True,
            rounded = True)

"""# M Model

## Regression Models
"""

# Using college data to train and nba data as target
def subset_model_PR(college_file, nba_file, k=9, test_size=0.2, random_state=42, new_data=None):
    # Load the data from the CSV files
    college_data = pd.read_csv(college_file)
    nba_data = pd.read_csv(nba_file)

    # Merge college_data with nba_data to get target variable (PR)

    #nba_data = nba_data[nba_data["PLAYER"] ==   TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'name']   ]

    perf = "PTS"

    merged_data = pd.merge(college_data, nba_data[['PLAYER',perf]], left_on='player_name', right_on='PLAYER')


    #TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), Xlist]

    # Drop any rows with missing target variable values
    merged_data = merged_data.dropna(subset=[perf])
    print(len(merged_data))
    merged_data = merged_data[merged_data['year'] < 2016]
    print(len(merged_data))

    merged_data = merged_data[merged_data['player_name'].isin(merged_df['name'])]

    #print(len(merged_data))
    #print(merged_data['year'].unique())
    # Split the data into features (X) and target (y)
    # Modify this line to drop only columns not relevant for training
    X = merged_data.drop(['player_name', 'PLAYER', perf, 'team', 'conf', 'Unnamed: 64', 'Unnamed: 65', 'yr', 'ht', 'type'], axis=1)
    #Xlist = list(X.columns)
    y = merged_data[perf]

    # The rest of your function can remain the same
    # Use feature selection to identify the most important features
    selector = SelectKBest(score_func=f_regression, k=k)

    # Impute missing values using mean strategy
    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')

    # Create a pipeline to handle feature selection and imputation
    pipeline = Pipeline([('imputer', imputer), ('selector', selector)])

    # Fit the pipeline on the data and transform it
    X_selected = pipeline.fit_transform(X, y)
    #print(X_selected)
    #print(type(X_selected))
    #print(X_selected.shape)
    # Get the indices and names of the most important features
    indices = selector.get_support(indices=True)
    feature_names = X.columns[indices]
    print(list(feature_names))
    # Split the subset of data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=test_size, random_state=random_state)

    # Train a machine learning model on the subset of data
    model = RandomForestRegressor(random_state=random_state)
    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)
    print(score)
    return model, list(feature_names)


PRModel, Xlist = subset_model_PR("/content/drive/MyDrive/448 - Project/CollegeBasketballPlayers2009-2021.csv", "/content/drive/MyDrive/448 - Project/ALL YEARS 2009 - 2022.csv", k=9)

def subset_model_all_features(college_file, nba_file, features, k=9, test_year=2016, test_size=0.2, random_state=42, new_data=None):
    # Load the data from the CSV files
    college_data = pd.read_csv(college_file)
    nba_data = pd.read_csv(nba_file)

    Models = {}
    FeatNames = {}
    for feat in features:
        # Find the latest year in college_data that is before the test_year
        year = college_data['year'].max()
        while year >= test_year:
            year -= 1

        # Merge college_data with nba_data to get target variable (PR)
        merged_data = pd.merge(college_data, nba_data[['PLAYER', feat]], left_on='player_name', right_on='PLAYER')

        # Drop any rows with missing target variable values
        merged_data = merged_data.dropna(subset=[feat])

        merged_data = merged_data[merged_data['year'] < 2016]
        merged_data = merged_data[merged_data['player_name'].isin(merged_df['name'])]


        # Split the data into features (X) and target (y)
        # Modify this line to drop only columns not relevant for training
        X = merged_data.drop(['player_name', 'PLAYER', feat, 'team', 'conf', 'Unnamed: 64', 'Unnamed: 65', 'yr', 'ht', 'type', 'year'], axis=1)
        y = merged_data[feat]
        print(X.shape)

        feature_names = X.columns
        print(list(feature_names))

        # The rest of your function can remain the same
        # Use feature selection to identify the most important features
        selector = SelectKBest(score_func=f_regression, k=k)

        # Impute missing values using mean strategy
        imputer = SimpleImputer(missing_values=np.nan, strategy='mean')

        # Create a pipeline to handle feature selection and imputation
        pipeline = Pipeline([('imputer', imputer), ('selector', selector)])

        # Fit the pipeline on the data and transform it
        X_selected = pipeline.fit_transform(X, y)

        # Get the indices and names of the most important features
        indices = selector.get_support(indices=True)
        feature_names = X.columns[indices]
        print(list(feature_names))
        # Split the subset of data into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=test_size, random_state=random_state)

        # Train a machine learning model on the subset of data
        model = RandomForestRegressor(random_state=random_state)
        model.fit(X_train, y_train)

        # Evaluate the model on the testing set
        score = model.score(X_test, y_test)
        Models[feat] = model
        FeatNames[feat] = list(feature_names)
        print(f"{feat}: {score}")
    return Models, FeatNames
MRegModels, Xlists = subset_model_all_features("/content/drive/MyDrive/448 - Project/CollegeBasketballPlayers2009-2021.csv", "/content/drive/MyDrive/448 - Project/ALL YEARS 2009 - 2022.csv", Performance, k=9)

print(Xlists)
print(MRegModels)

"""## Classification Models"""

def neural_network_model_classification(csv_file, nba_file, features, test_year, test_size=0.2, random_state=42):
    # Load the data from the CSV files
    college_data = pd.read_csv(csv_file, low_memory=False)
    nba_data = pd.read_csv(nba_file)

    # Initialize an empty dictionary to store accuracy scores
    scores = {}
    Models = {}
    FeatNames = {}

    for feat in features:
        # Find the latest year in college_data that is before the test_year
        year = college_data[college_data['year'] < test_year]['year'].max()

        # Merge college_data with nba_data to get target variables (above/below median)
        merged_data = pd.merge(college_data, nba_data[['PLAYER', feat]], left_on='player_name', right_on='PLAYER')

        # Drop any rows with missing target variable values
        merged_data = merged_data.dropna(subset=[feat])

        merged_data = merged_data[merged_data['year'] < 2016]
        #merged_data = merged_data[merged_data['player_name'].isin(merged_df['name'])]




        # Calculate the median of the target variable
        target_median = merged_data[feat].mean()

        # Classify the samples as above or below median
        merged_data['target'] = merged_data[feat].apply(lambda x: 1 if x >= target_median else 0)

        # Split the data into features (X) and target (y)
        X = merged_data.drop(['player_name', 'PLAYER', 'team', 'target', 'conf', 'Unnamed: 64', 'Unnamed: 65', 'year', 'yr', 'ht', 'type', feat], axis=1)
        y = merged_data['target']
        print(X.shape)


        feature_names = X.columns
        print(list(feature_names))


        # Impute missing values using mean strategy
        imputer = SimpleImputer(missing_values=np.nan, strategy='median')
        X = imputer.fit_transform(X)

        # Standardize the features
        scaler = StandardScaler()
        X = scaler.fit_transform(X)

        # Split the data into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

        # Train a neural network model on the training set
        model = MLPClassifier(hidden_layer_sizes=(100,100), max_iter=100, random_state=random_state)
        model.fit(X_train, y_train)

        # Evaluate the model on the testing set
        score = model.score(X_test, y_test)


        Models[feat] = model
        FeatNames[feat] = list(feature_names)
        print(f"{feat}: {score}")
    return Models, FeatNames

MClassModels, XClasslist = neural_network_model_classification("/content/drive/MyDrive/448 - Project/CollegeBasketballPlayers2009-2021.csv", "/content/drive/MyDrive/448 - Project/ALL YEARS 2009 - 2022.csv", Performance, test_year=2016)



"""# TM Model"""



"""## Regression Models"""

#Performance = ['PTS']

from statsmodels.api import OLS
import statsmodels.api as sm
FusionModels = {}
for i, perf in enumerate(Performance):
  #print(perf)
  X_forT = ALL_TEST[RegEmbedding[i]][0:82, :]
  X_forM = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), Xlists[perf]].head(82)

  #print(type(X_forM))
  Tmodel = TRegModels[perf]
  Mmodel = MRegModels[perf]
  y = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'{perf}'].head(82).values
  #print(f"This is y shape{y.shape}")
  Tprediction = Tmodel.predict(X_forT)
  Mprediction = Mmodel.predict(X_forM)

  #print(type(Tprediction))
  #print(Tprediction)
  #print(Tprediction.shape)
  #print(Mprediction.shape)

  X = np.stack((Tprediction, Mprediction), axis=1) #combine Tpredict and Mpredict
  #print(X.shape)

  fusionModel = LinearRegression()
  scores = cross_validate(fusionModel, X, y, cv=10, return_estimator=True)
  mean_performance = scores['test_score'].mean()
  if perf == "FG%":
    mean_performance = scores['test_score'][~4].mean()


  print(f"mean_performance for {perf} TM Model: {mean_performance}")
  bestModelIndex = np.argmax(scores['test_score'])
  print(scores['test_score'])
  fusionModel = scores["estimator"][bestModelIndex]
  FusionModels[perf] = fusionModel
  print(f"And the Coefficients are: {fusionModel.coef_}")

  coefficients = fusionModel.coef_
  intercept = fusionModel.intercept_

  X_with_intercept = sm.add_constant(X)

  # Fit the ordinary least squares (OLS) model
  ols_model = sm.OLS(y, X_with_intercept).fit()

  # Get the p-values for the predictors (coefficients)
  p_values = ols_model.pvalues[1:]  # Exclude the intercept

  # Print the p-values
  print("P-values: ", p_values)



  #mean_performance = scores['test_score'][bestModelIndex]

  #print(mean_performance)

print(X.shape)

OLS(y,sm.add_constant(X)).fit().summary()



"""## Classification Model"""



FusionClassModels = {}
for i, perf in enumerate(Performance):
  #print(perf)
  X_forT = ALL_TEST[ClassEmbedding[perf]][0:82, :]
  X_forM = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), XClasslist[perf]].head(82)

  #print(type(X_forM))
  Tmodel = TClassModels[perf]
  Mmodel = MClassModels[perf]
  y = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'AoB{perf}'].head(82).values
  #print(f"This is y shape{y.shape}")
  Tprediction = Tmodel.predict(X_forT)
  Mprediction = Mmodel.predict(X_forM)

  #print(type(Tprediction))
  #print(Tprediction)
  #print(Tprediction.shape)
  #print(Mprediction.shape)

  X = np.stack((Tprediction, Mprediction), axis=1) #combine Tpredict and Mpredict
  #print(X.shape)

  fusionModel = LogisticRegression()
  scores = cross_validate(fusionModel, X, y, cv=10, return_estimator=True)
  mean_performance = scores['test_score'].mean()
  print(f"mean_performance for {perf} TM Model: {mean_performance}")
  bestModelIndex = np.argmax(scores['test_score'])
  #print(scores['test_score'])
  fusionModel = scores["estimator"][bestModelIndex]
  FusionClassModels[perf] = fusionModel
  print(f"And the Coefficients are: {fusionModel.coef_}")


  # coefficients = fusionModel.coef_.ravel()
  # intercept = fusionModel.intercept_[0]

  # X_with_intercept = sm.add_constant(X)

  # # Fit the ordinary least squares (OLS) model
  # ols_model = sm.Logit(y, X_with_intercept).fit()

  # # Get the p-values for the predictors (coefficients)
  # p_values = ols_model.pvalues[1:]  # Exclude the intercept

  # # Print the p-values
  # print("P-values: ", p_values)

"""# Testing Model

## Regression Models
"""





for i, perf in enumerate(Performance):
  y_test = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'{perf}'].tail(49).values

  X_testforT = ALL_TEST[RegEmbedding[i]][82:, :]
  currentT_model = TRegModels[perf]
  Tprediction = currentT_model.predict(X_testforT)

  X_forM = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), Xlists[perf]].tail(49)
  Mmodel = MRegModels[perf]
  Mprediction = Mmodel.predict(X_forM)

  print(Tprediction.shape, Mprediction.shape)

  X = np.stack((Tprediction, Mprediction), axis=1)

  score = FusionModels[perf].score(X, y_test)

  #accuracy = (y_pred == y_test).mean()
  print(f"{perf} score: {score}")
  #print(f"Using {embedding}, the test accuracy for AoB{perf} was: {accuracy}")

for i, perf in enumerate(Performance):
  y_test = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'{perf}'].tail(49).values

  X_testforT = ALL_TEST[RegEmbedding[i]][82:, :]
  currentT_model = TRegModels[perf]
  Tprediction = currentT_model.predict(X_testforT)




  score = currentT_model.score(X_testforT, y_test)

  #accuracy = (y_pred == y_test).mean()
  print(f"{perf} score: {score}")
  #print(f"Using {embedding}, the test accuracy for AoB{perf} was: {accuracy}")

for performanceIndex, perf in enumerate(Performance):
  y_test = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'{perf}'].tail(49).values


  X_forM = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), Xlists[perf]].tail(49)
  Mmodel = MRegModels[perf]
  score = Mmodel.score(X_forM, y_test)

  #accuracy = (y_pred == y_test).mean()
  print(f"{perf} score {score}")
  #print(f"Using {embedding}, the test accuracy for AoB{perf} was: {accuracy}")

"""## Classification Models"""

for i, perf in enumerate(Performance):
  y_test = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'AoB{perf}'].tail(49).values

  X_testforT = ALL_TEST[ClassEmbedding[perf]][82:, :]
  currentT_model = TClassModels[perf]
  Tprediction = currentT_model.predict(X_testforT)

  X_forM = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), XClasslist[perf]].tail(49)
  Mmodel = MClassModels[perf]
  Mprediction = Mmodel.predict(X_forM)

  print(Tprediction.shape, Mprediction.shape)

  X = np.stack((Tprediction, Mprediction), axis=1)

  score = FusionClassModels[perf].score(X, y_test)

  #accuracy = (y_pred == y_test).mean()
  print(f"{perf} score: {score}")
  #print(f"Using {embedding}, the test accuracy for AoB{perf} was: {accuracy}")

for i, perf in enumerate(Performance):
  y_test = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'AoB{perf}'].tail(49).values

  X_testforT = ALL_TEST[ClassEmbedding[perf]][82:, :]
  currentT_model = TClassModels[perf]
  Tprediction = currentT_model.predict(X_testforT)


  score = currentT_model.score(X_testforT, y_test)

  #accuracy = (y_pred == y_test).mean()
  print(f"{perf} score: {score}")

for i, perf in enumerate(Performance):
  y_test = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'AoB{perf}'].tail(49).values


  X_forM = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), XClasslist[perf]].tail(49)
  Mmodel = MClassModels[perf]
  Mprediction = Mmodel.predict(X_forM)


  score = Mmodel.score(X_forM, y_test)

  #accuracy = (y_pred == y_test).mean()
  print(f"{perf} score: {score}")