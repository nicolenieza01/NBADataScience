# -*- coding: utf-8 -*-
"""ExtractInterview.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ole2KDvy0mqte72pWjRbBSO2I_Apcis6
"""



import requests
from bs4 import BeautifulSoup

url = "http://www.asapsports.com/show_year.php?category=11&year=2008"

response = requests.get(url)
soup = BeautifulSoup(response.content, "html.parser")

print(soup)

all_a = soup.find_all("a")

print(str(all_a[1]))

desired_link = ""
for a in all_a:
  if "NBA DRAFT" in str(a):
    desired_link = str(a)
    break

desired_link

left_bound = desired_link.find("=")
right_bound = desired_link.find(">")

print(desired_link)
new_link = desired_link[left_bound + 2:right_bound - 1].replace("amp", "").replace(";", "")
print(new_link)

new_linkresponse = requests.get(new_link)
new_linksoup = BeautifulSoup(new_linkresponse.content, "html.parser")

print(new_linksoup)

all_a_new_link = new_linksoup.find_all("a")

actual_desired_link = ""
for a in all_a_new_link:
  if "NBA DRAFT" in str(a):
    actual_desired_link = str(a)
    break

print(actual_desired_link)
left_bounda = actual_desired_link.find("=")
right_bounda = actual_desired_link.find(">")
draft_link = actual_desired_link[left_bounda + 2:right_bounda - 1].replace("amp", "").replace(";", "")
print(draft_link)

draftresponse = requests.get(draft_link)
draftsoup = BeautifulSoup(draftresponse.content, "html.parser")

print(draftsoup)

player_links = []
player_names = []


draft_a = draftsoup.find_all("a")


for a in draft_a:
  a_str = str(a)
  if "show_i" in a_str:
    #print(a)
    left_equals = a_str.find("=")
    right_arrow = a_str.find(">")
    player_link = a_str[left_equals + 2:right_arrow - 1].replace("amp", "").replace(";", "")
    #print(player_link)
    player_links.append(player_link)
    next_right = a_str[right_arrow + 1:].find("<")
    player_name = (a_str[right_arrow + 1: right_arrow + 1 + next_right])
    #print(player_name)
    player_names.append(player_name)

print(player_links)
print(player_names)

current_player_link = player_links[4]

playerresponse = requests.get(current_player_link)
playersoup = BeautifulSoup(playerresponse.content, "html.parser")

print(playersoup)

player_text = playersoup.get_text()
first_q = player_text.find("Q")
mention_scripts = player_text[first_q:].find("Scripts")
almost_there_string = player_text[first_q:first_q + mention_scripts]


#print(almost_there_string)

# Split the text into lines
lines = almost_there_string.splitlines()

# Remove the last line
lines = lines[:-1]

# Join the remaining lines back into a single string
desired_text = "\n".join(lines)


print(desired_text)

data = {}
for index, current_player_link in enumerate(player_links):
  playerresponse = requests.get(current_player_link)
  playersoup = BeautifulSoup(playerresponse.content, "html.parser")

  player_text = playersoup.get_text()
  first_q = player_text.find("Q")
  mention_scripts = player_text[first_q:].find("Scripts")
  almost_there_string = player_text[first_q:first_q + mention_scripts]


  #print(almost_there_string)

  # Split the text into lines
  lines = almost_there_string.splitlines()

  # Remove the last line
  lines = lines[:-1]

  # Join the remaining lines back into a single string
  desired_text = "\n".join(lines)


  #print(desired_text)
  data[player_names[index]] = {"link": current_player_link, "text": desired_text}

#print(data["Russell Westbrook"]["text"])

"""Now the actual extraction:"""

import pickle
import requests
from bs4 import BeautifulSoup

def get_NBA_draft_link(soup):
  all_a = soup.find_all("a")
  desired_links = []
  for a in all_a:
    if "NBA DRAFT" in str(a):
      desired_link = str(a)
      left_bound = desired_link.find("=")
      right_bound = desired_link.find(">")
      new_link = desired_link[left_bound + 2:right_bound - 1].replace("amp", "").replace(";", "")
      desired_links.append(new_link)

  return desired_links

lower_year = 2006
upper_year = 2022
file_number = 0

ALL_DATA = {}


for year in range(lower_year, upper_year + 1):
  original_url = "http://www.asapsports.com/show_year.php?category=11&year=" + str(year)

  original_response = requests.get(original_url)
  original_soup = BeautifulSoup(original_response.content, "html.parser")

  intermediate_urls = get_NBA_draft_link(original_soup)
  int_url = intermediate_urls[0]
  int_response = requests.get(int_url)
  int_soup = BeautifulSoup(int_response.content, "html.parser")

  draft_urls = get_NBA_draft_link(int_soup)

  data = {}
  for draftlink in draft_urls:
    draftresponse = requests.get(draftlink)
    draftsoup = BeautifulSoup(draftresponse.content, "html.parser")


    player_links = []
    player_names = []


    draft_a = draftsoup.find_all("a")


    for a in draft_a:
      a_str = str(a)
      if "show_i" in a_str:
        #print(a)
        left_equals = a_str.find("=")
        right_arrow = a_str.find(">")
        player_link = a_str[left_equals + 2:right_arrow - 1].replace("amp", "").replace(";", "")
        #print(player_link)
        player_links.append(player_link)
        next_right = a_str[right_arrow + 1:].find("<")
        player_name = (a_str[right_arrow + 1: right_arrow + 1 + next_right])
        #print(player_name)
        player_names.append(player_name)


    for index, current_player_link in enumerate(player_links):
      playerresponse = requests.get(current_player_link)
      playersoup = BeautifulSoup(playerresponse.content, "html.parser")

      player_text = playersoup.get_text()
      first_q = player_text.find("Q.")
      mention_scripts = player_text[first_q:].find("Scripts")
      almost_there_string = player_text[first_q:first_q + mention_scripts]

      # Split the text into lines
      lines = almost_there_string.splitlines()

      # Remove the last line
      lines = lines[:-1]

      # Join the remaining lines back into a single string
      desired_text = "\n".join(lines)


      #print(desired_text)
      data[player_names[index]] = {"link": current_player_link, "text": desired_text}

  ALL_DATA[year] = data
  if (year - lower_year)  % 3 == 0:
    print(f"Completed {(year - lower_year)} years")
    filename = 'PartialInterviews' + str((year - lower_year)) + '.pkl'
    f =  open(filename, 'wb')
    pickle.dump(ALL_DATA, f)
    print(f"Saved file {filename}")
    f.close()

ALL_KEYS = ALL_DATA.keys()
print(ALL_KEYS)
p = ALL_DATA[2020].keys()
print(p)

total = 0
for key in ALL_DATA.keys():
  p = ALL_DATA[key].keys()
  print(len(p))
  total += len(p)
print(total)

print(f"Completed {(year - lower_year)} years")
filename = 'RookieInterviews_2006_2022'  + '.pkl'
f =  open(filename, 'wb')
pickle.dump(ALL_DATA, f)
print(f"Saved file {filename}")

print(ALL_DATA[2017]["Dennis Smith, Jr."])

import pandas as pd

filename = 'RookieInterviews_2006_2022'  + '.pkl'
objects = []
with (open(filename, "rb")) as openfile:
    while True:
        try:
            objects.append(pickle.load(openfile))
        except EOFError:
            break

print(objects[0])

for year in objects[0].keys():
  for player in objects[0][year].keys():
    objects[0][year][player]['text'] = objects[0][year][player]['text'].replace('\n', ' ')


print(objects[0][2006]['Shelden Williams']['text'])